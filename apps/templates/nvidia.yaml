{{- if (index .Values "nvidia" "enable") }}
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: nvidia
  namespace: argo
spec:
  destination:
    namespace: nvidia
    server: {{ .Values.spec.destination.server }}
  project: default
  sources:
    - repoURL: https://nvidia.github.io/k8s-device-plugin
      chart: nvidia-device-plugin
      targetRevision: {{ (index .Values "nvidia" "targetRevision") }}
      helm:
        values: |
          nodeSelector:
            gpu: "true"
          priorityClassName: ""
          tolerations:
          - key: nvidia.com/gpu
            operator: Exists
            effect: NoSchedule
          config:
            deviceDiscoveryStrategy: "nvml"  # Make sure this is consistent
            plugin:
              nvidiaCTKPath: "/usr/bin/nvidia-ctk"
              containerDriverRoot: "/run/nvidia/driver"  # Add this if needed
      name: device-plugin
    - repoURL: https://helm.ngc.nvidia.com/nvidia
      chart: gpu-operator
      targetRevision: {{ (index .Values "nvidia" "operatorRevision") }}
      helm:
        values: |
          driver:
            enabled: false
          devicePlugin:
            enabled: false
          migManager:
            enabled: false
          nodeSelector:
            gpu: "true"
          # Explicitly set container runtime
          toolkit:
            enabled: true
            env:
            - name: CONTAINER_RUNTIME
              value: containerd
            - name: CONTAINERD_CONFIG
              value: /var/lib/rancher/k3s/agent/etc/containerd/config.toml
            - name: CONTAINERD_SOCKET
              value: /run/k3s/containerd/containerd.sock
            - name: NVIDIA_VISIBLE_DEVICES
              value: all
            - name: NVIDIA_DRIVER_CAPABILITIES
              value: compute,utility
      name: gpu-operator
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
{{- end }}
